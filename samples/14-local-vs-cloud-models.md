# Local vs Cloud AI Models

Choose between privacy-first local deployment and powerful cloud models based on your needs.

```typescript
import { AIAgent, AIGNE } from "@aigne/core";
import { OpenAIChatModel } from "@aigne/openai";
import { OllamaChatModel } from "@aigne/ollama";

// Privacy-first local deployment (offline, no data sent externally)
const localAigne = new AIGNE({
  model: new OllamaChatModel({
    baseURL: "http://localhost:11434",
    model: "llama3", // Runs entirely on your machine
  }),
});

// Cloud-powered enterprise solution
const cloudAigne = new AIGNE({
  model: new OpenAIChatModel({
    model: "gpt-4o", // Latest cloud AI capabilities
  }),
});

const agent = AIAgent.from({
  instructions: "You are a coding assistant",
  inputKey: "message",
});

// Local processing - completely private
const localResult = await localAigne.invoke(agent, {
  message: "Review this sensitive code"
});

// Cloud processing - maximum performance
const cloudResult = await cloudAigne.invoke(agent, {
  message: "Generate a complex algorithm"
});
```

## Twitter Post #1

ğŸ  Privacy vs â˜ï¸ Power with AIGNE!

Local Ollama:
ğŸ”’ 100% private & offline
ğŸ’° No API costs
ğŸ›¡ï¸ Full data control

Cloud OpenAI:
ğŸš€ Latest AI capabilities
âš¡ Unlimited scale
ğŸ“Š Best performance

One codebase, flexible deployment! ğŸš€

#AIGNE #ArcBlock #LocalAI

## Twitter Post #2

This example shows local vs cloud model deployment:

â€¢ Use OllamaChatModel for local privacy
â€¢ Use OpenAIChatModel for cloud power
â€¢ Identical code for both approaches
â€¢ Choose based on your needs

Which approach fits your needs better? ğŸ¤”

## Twitter Post #3

Checkout our repo: https://github.com/aigne-io/aigne-framework
